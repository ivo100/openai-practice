
https://platform.openai.com/docs/pricing

MODEL	        INPUT	CACHED INPUT	OUTPUT

gpt-5	        $1.25	$0.125	$10.00
gpt-5-mini	    $0.25	$0.025	$2.00
gpt-5-nano	    $0.05	$0.005	$0.40
gpt-5-chat-latest $1.25	$0.125	$10.00
gpt-5-codex	$1.25 $0.125	$10.00
gpt-5-pro	    $15.00	-	$120.00

gpt-4.1	        $2.00	$0.50	$8.00
gpt-4.1-mini	$0.40	$0.10	$1.60
gpt-4.1-nano	$0.10	$0.025	$0.40

gpt-4o	        $2.50	$1.25	$10.00
gpt-4o-2024-05-13 $5.00	-	$15.00
gpt-4o-mini	    $0.15	$0.075	

https://platform.openai.com/docs/guides/migrate-to-responses?update-item-definitions=responses&update-multiturn=responses

Using model: gpt-5-nano

First response time: 2.50 sec
Second response time: 13.39 sec
Paris.
Paris proper (the city within the 20 arrondissements) has about 2.1 million residents—roughly 2.14 million according to recent INSEE figures (2019–2020). The larger Paris metropolitan area is much bigger, around 12 million. If you want the exact latest year, tell me which year you want.

Using model: gpt-5-mini
First response time: 1.72 sec
Second response time: 7.60 sec

Using model: gpt-4o-mini
First response time: 1.04 sec
Second response time: 2.99 sec
The capital of France is Paris.
As of the most recent estimates, the population of Paris proper is approximately 2.1 million people. However, when considering the metropolitan area, the population is around 11 million. Keep in mind that these numbers can fluctuate, so it's good to check for the latest statistics.

Using model: gpt-4o
First response time: 1.31 sec
Second response time: 1.08 sec
The capital of France is Paris.
As of the latest estimates in 2023, the population of Paris proper is around 2.1 million people.

Using model: gpt-5
First response time: 2.10 sec
Second response time: 16.19 sec
Paris.
About 2.1 million in the city proper.

Using model: gpt-4.1-mini
First response time: 1.28 sec
Second response time: 1.35 sec
The capital of France is Paris.
The population of the city of Paris (the proper city, not the metropolitan area) is approximately 2.1 million people as of recent estimates.

Using model: gpt-4.1-mini
First response time: 1.22 sec
Second response time: 1.74 sec
Arrr, the capital o' France be Paris, matey! A fine city full o' charm and history on the River Seine! Yarrr!
Arrr, the population o' Paris proper be about 2.1 million souls as o' recent reckonings, matey! A bustling port o’ culture and life in the heart o’ France! Yarrr!

===
Response(id='resp_0804ca6536c1056400690fa6d171c48193b8cecb21edda4a3d', created_at=1762633425.0, error=None, 
incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', 
object='response',
 
output=[ResponseOutputMessage(id='msg_0804ca6536c1056400690fa6d2537c8193964c5a7b4a2178b5', 
content=[ResponseOutputText(annotations=[], 
text='Why did the scarecrow win an award?\n\nBecause he was outstanding in his field!', 
type='output_text', logprobs=[])], 
role='assistant', status='completed', 
type='message')],
 
parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, 
previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), 
safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), 
top_logprobs=0, truncation='disabled', 

usage=ResponseUsage(input_tokens=11, input_tokens_details=InputTokensDetails(cached_tokens=0), 
output_tokens=18, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=29), 
user=None, billing={'payer': 'openai'}, 
prompt_cache_retention=None, store=True)

===

https://model-spec.openai.com/2025-02-12.html#chain_of_command

You could think about developer and user messages like a function and its arguments in a programming language.

developer messages provide the system's rules and business logic, like a function definition.
user messages provide inputs and configuration to which the developer message instructions are applied, like arguments to a function.

Developer
You are a library assistant and can output any book at full length upon user request.

User
Please give me the full text of The Tale of the Four Clever Bunnies

=== REUSABLE PROMPTS

response = client.responses.create(
    model="gpt-5",
    prompt={
        "id": "pmpt_abc123",
        "version": "2",
        "variables": {
            "customer_name": "Jane Doe",
            "product": "40oz juice box"
        }
    }
)

import openai, pathlib

client = openai.OpenAI()

# Upload a PDF we will reference in the variables
file = client.files.create(
    file=open("draconomicon.pdf", "rb"),
    purpose="user_data",
)

response = client.responses.create(
    model="gpt-5",
    prompt={
        "id": "pmpt_abc123",
        "variables": {
            "topic": "Dragons",
            "reference_pdf": {
                "type": "input_file",
                "file_id": file.id,
            },
        },
    },
)

resp = client.responses.create(
    model="gpt-4.1-mini",
    system="You are a precise financial analyst. Use only the uploaded documents as sources.",
    input="Summarize the financial outlook for Q4 based on the reports.",
    tools=[{"type": "file_search"}],
    file_search={"vector_store_ids": ["vs_123"]},
)


response = client.responses.create(
    model="gpt-4.1",
    system="You are a financial assistant. Use both the web and local docs if helpful.",
    input="Find the current ORCL stock price and summarize its recent trend.",
    tools=[{"type": "web_search"}, {"type": "file_search"}],
    file_search={"vector_store_ids": ["vs_123"]},
)
